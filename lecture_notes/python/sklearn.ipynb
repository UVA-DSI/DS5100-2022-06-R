{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to sklearn\n",
    "### University of Virginia\n",
    "### Programming for Data Science\n",
    "### Last Updated: November 8, 2021\n",
    "---  \n",
    "\n",
    "### PREREQUISITES\n",
    "- variables\n",
    "- data types\n",
    "- pandas\n",
    "\n",
    "### SOURCES \n",
    "- [sklearn Introduction](https://scikit-learn.org/stable/index.html)\n",
    "- [R-Squared in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)\n",
    "- [sklearn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "\n",
    "### OBJECTIVES\n",
    "- Introduce some basic functionality of the `sklearn` package\n",
    "- Illustrate how to fit a regression model with `sklearn`\n",
    "- Illustrate how to prepare data and fit a regression model with `sklearn` using Pipelines\n",
    "\n",
    "### CONCEPTS\n",
    "- `sklearn` interface\n",
    "- Pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction to sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scikit-learn` package - shortened to `sklearn` - provides nice functionality for machine learning.  \n",
    "It also includes a nice Pipeline object for facilitated construction and persistance of models.  \n",
    "This notebook will provide a very brief demo of `sklearn`. You are encouraged to explore and go further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocess Data and Fit a Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sklearn dataset and functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score # R-squared\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect what's in the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(housing.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*housing.data* contains the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "          37.88      , -122.23      ],\n",
       "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "          37.86      , -122.22      ],\n",
       "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "          37.85      , -122.24      ],\n",
       "       ...,\n",
       "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "          39.43      , -121.22      ],\n",
       "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "          39.43      , -121.32      ],\n",
       "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "          39.37      , -121.24      ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 60% train, 40% test sets. The helper function `train_test_split` is helpful for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(housing.data, housing.target, train_size = 0.6, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12384, 8256, 12384, 8256)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following:\n",
    "- scale the x_train and x_test data using `StandardScaler`\n",
    "- train a regression model on (x_train, y_train)\n",
    "- predict on x_test\n",
    "- evaluate performance against y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate StandardScaler object and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the scaled training data. Computing column means and standard deviations, we see the data is now centered and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.41768936e-01,  8.97274139e-01, -1.85640214e-02, ...,\n",
       "        -4.28501066e-02, -2.20840635e-01,  5.77185876e-02],\n",
       "       [-4.42312682e-01,  1.85379671e+00, -1.21232764e-01, ...,\n",
       "         1.15088564e-02,  1.75535469e+00, -9.08412716e-01],\n",
       "       [-1.21121241e+00, -9.36060779e-01, -7.45820655e-01, ...,\n",
       "         1.34336061e-01,  7.71939953e-01, -4.52879304e-01],\n",
       "       ...,\n",
       "       [ 2.88703976e-01, -1.09548121e+00,  2.45801399e-01, ...,\n",
       "         6.25970319e-02, -7.68743129e-01,  1.03886748e+00],\n",
       "       [-4.89745665e-01,  2.04617870e-02, -3.46951864e-01, ...,\n",
       "        -8.33657386e-02,  4.53500897e-01, -1.16371166e+00],\n",
       "       [ 1.44241788e-01,  2.59592428e-01,  8.92070260e-04, ...,\n",
       "        -6.70406776e-02, -1.40562124e+00,  1.25411953e+00]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.39298549e-15, -1.02774522e-16, -1.06658763e-14, -5.55920742e-15,\n",
       "       -1.52942545e-17, -7.05635754e-16,  9.44804814e-15, -8.41492753e-14])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_s.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_s.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Logistic Regression model and fit it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the passed data matters: (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train_s, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the predictor coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81403101,  0.11883616, -0.260123  ,  0.31025271, -0.00178077,\n",
       "       -0.04600269, -0.91689468, -0.88930004])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.060088804909497"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions on training set (use *x_train_s* to predict *y_train*). These are optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = reg.predict(x_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure R-squared on train set. Note the order is y_true, y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6039404342150474\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRY FOR YOURSELF\n",
    "Do the following:\n",
    "\n",
    "- Import your own dataset\n",
    "- Use `sklearn` to split the data, scale it, fit a model, and compute a measure of model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Set up a Pipeline to Prep Data and Fit a Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pipeline in machine learning gives many strong benefits:\n",
    "\n",
    "- it keeps all of the steps together (data processing and the algorithm). as complexity increases, the benefit really kicks in.\n",
    "- the pipeline can be tuned during fitting (e.g., k-fold cross validation can be included, and the best model returned)\n",
    "- the model can be saved, loaded, and reused\n",
    "- the model can be applied to new data for scoring (inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operationally, the pipeline object takes a list of tuples, where each tuple consists of two things: 1) the step's name 2) the transformer/algorithm.\n",
    "\n",
    "The step's name is arbitrarily set by the user.\n",
    "\n",
    "The example below replicates the work from section II. It is expected to give identical results.\n",
    "\n",
    "Note that a model can include many preprocessing steps (even custom Transformer steps), and the pipeline keeps things very tidy and manageable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                 ('scaler', StandardScaler()), \n",
    "                 ('reg', LinearRegression())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('reg',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict based on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8550803 , 1.04750294, 0.81125812, ..., 1.82417837, 2.37188604,\n",
       "       2.37648592])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the predictions from the original regression model without the pipeline. They should match, and they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8550803 , 1.04750294, 0.81125812, ..., 1.82417837, 2.37188604,\n",
       "       2.37648592])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(x_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the score, which is the R-squared. Again, this matches the original regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6039404342150474"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRY FOR YOURSELF\n",
    "Do the following:\n",
    "\n",
    "- Using the dataset you imported earlier, build a pipeline to scale the data, fit a model, and compute a measure of model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
